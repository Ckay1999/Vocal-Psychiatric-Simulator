{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocal Psychiatric Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART - A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using SVM (without libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Use Matplotlib in jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math behind SVM\n",
    "#### Loss Function ####\n",
    "I use the Hinge Loss which is used for training classifiers and used for \"maximum-margin\" which is mostly usable for Support Vector Machines.\n",
    "\n",
    "#### Loss Function ####\n",
    "Hinge loss is shown as:\n",
    "<img src=\"hingeloss.png\"> \n",
    "where: \n",
    "- c is loss function,\n",
    "- x is the vector of coordinates of point,\n",
    "- y is the correct label of point and,\n",
    "- f(x) is the label the SVM predicts\n",
    "\n",
    "#### Objective Function ####\n",
    "Objective Function conteins two terms: The first term is a regularizer, and the second term the loss. \n",
    "<img src=\"objectivefunc.png\">\n",
    "The part after the + sign is the loss function hinge loss, and the part before the + sign is the regularizer. Regularizer balances the margin maximization and loss.\n",
    "\n",
    "#### Minimize Loss ####\n",
    "To minimize loss, I will use gradient descent.\n",
    "<img src=\"gradient.png\">\n",
    "\n",
    "#### At the end... ####\n",
    "At the end, we have a formula:\n",
    "<img src=\"formula.png\">\n",
    "where:\n",
    "- w is weight of SVM,\n",
    "- n is the learning rate\n",
    "- lambda is the 1/epoch (change rate gets smaller while it pass epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Class\n",
    "#### - consists of function for TRAINING, PREDICTION, ACCURACY, PLOTTING WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svm_classifier:\n",
    "    '''\n",
    "    @class : svm_classifier\n",
    "    @Description : This class consists of all the functions used to build Support-Vector Machine Classifier\n",
    "    \n",
    "    @Number of functions : 5\n",
    "    \n",
    "    @Class variables : 1. learning_rate = learning rate for the model\n",
    "                      \n",
    "    @Author : Anchit, Adit, Ankita, Chahat\n",
    "    '''\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def __init__(self, learning_rate):\n",
    "        '''\n",
    "        @function name : __init__ \n",
    "        @Description : default function used to initialize class variables\n",
    "        \n",
    "        @Return : none\n",
    "        '''\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def train(self, X, Y, epochs = 10000):\n",
    "        '''\n",
    "        @function name : train\n",
    "        @Description : this function is used to train the SVM model and then set the weight matrix accordingly\n",
    "        \n",
    "        @Return : weight matrix\n",
    "        '''\n",
    "        \n",
    "        #Initialize our SVMs weight vector with zeros (3 values)\n",
    "        w = np.zeros(len(X[0]))\n",
    "    \n",
    "        # class-wise weight matrix\n",
    "        w0_per_epoch = []\n",
    "        w1_per_epoch = []\n",
    "    \n",
    "        # Training\n",
    "        print(\"starts training\")\n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            accuracy = []\n",
    "            for i, x in enumerate(X):\n",
    "                # If there is an error\n",
    "                if (Y[i] * np.dot(X[i], w)) < 1:\n",
    "                    w = w + self.learning_rate * ((X[i] * Y[i]) + (-2 * (1/epochs) * w))\n",
    "                    accuracy.append(0)\n",
    "                else:\n",
    "                    w = w + self.learning_rate * (-2 * (1/epochs) * w)\n",
    "                    accuracy.append(1)\n",
    "                \n",
    "            w0_per_epoch.append(w[0])\n",
    "            w1_per_epoch.append(w[1])\n",
    "            epoch_accuracy = round(sum(accuracy) / len(accuracy) * 100, 3)\n",
    "            \n",
    "            print(f\"Epoch {epoch}/{epochs} ....... Training Done ....... Accuracy = {epoch_accuracy}\")\n",
    "        \n",
    "        print(\"stops training\")\n",
    "        return w, w0_per_epoch, w1_per_epoch\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def plot_weights(self, w0array, w1array):\n",
    "        '''\n",
    "        @function name : plot_weights\n",
    "        @Description : this function is used to plot the weight matrix\n",
    "        \n",
    "        @Return : none\n",
    "        '''\n",
    "        \n",
    "        # You cannot see anything in the graph of 10000 numbers :)\n",
    "        epochs = len(w0array)\n",
    "\n",
    "        # It will divide epochs to this number\n",
    "        number_of_weights_to_graph = 100\n",
    "\n",
    "        num_per_epoch = epochs/number_of_weights_to_graph\n",
    "\n",
    "        w0_to_graph = []\n",
    "        w1_to_graph = []\n",
    "        epoch_to_graph = []\n",
    "\n",
    "        for i in range(number_of_weights_to_graph):\n",
    "            epoch_to_graph.append(int(num_per_epoch*i))\n",
    "            w0_to_graph.append(w0array[int(num_per_epoch*i)])\n",
    "            w1_to_graph.append(w1array[int(num_per_epoch*i)])\n",
    "    \n",
    "        plt.plot(epoch_to_graph, w0_to_graph, 'r',epoch_to_graph, w1_to_graph,'b')\n",
    "        \n",
    "    ###########################################################################################################\n",
    "    def predict(self, x, w, threshold = 0):\n",
    "        '''\n",
    "        @function name : predict\n",
    "        @Description : this function is used to predict output labels on the test set\n",
    "        \n",
    "        @Return : list for the predicted labels\n",
    "        '''\n",
    "        \n",
    "        #y_pred = np.dot(x[0], w)\n",
    "        \n",
    "        if(np.dot(x[0], w)) <= threshold:\n",
    "            y_pred = -1\n",
    "        else:\n",
    "            y_pred = 1\n",
    "    \n",
    "        return y_pred\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def accuracy(self, y, y_pred):\n",
    "        '''\n",
    "        @function name : accuracy\n",
    "        @Description : this function is used to calculate the accuracy for the model\n",
    "        \n",
    "        @Return : accuracy percentage\n",
    "        '''\n",
    "        \n",
    "        result = 0\n",
    "        length = len(y)\n",
    "        for i in range(0, length):\n",
    "            if (y[i] * y_pred[i] == 1):\n",
    "                result += 1\n",
    "    \n",
    "        return ((result/length) * 100)\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def transpose(self, A):\n",
    "        '''\n",
    "        @function name : transpose\n",
    "        @Description : this function is used to transpose a matrix, array or vector\n",
    "        \n",
    "        @Return : transposed numpy array\n",
    "        '''\n",
    "        X = np.zeros([1, len(A)], dtype = float)\n",
    "        for i in range(0, len(A)):\n",
    "            X[0][i] = A[i]\n",
    "        \n",
    "        return np.array(X)\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    def padding(self, x, w):\n",
    "        '''\n",
    "        @function name : padding\n",
    "        @Description : this function is used to add padding to the data tuples for dot-product compatibility\n",
    "\n",
    "        @Return : padded numpy array\n",
    "        '''\n",
    "        rx, cx = x.shape\n",
    "        rw = w.shape\n",
    "        xLIST = x.tolist()\n",
    "\n",
    "        for i in range(0, rx):\n",
    "            for j in range(0, (rw[0] - cx)):\n",
    "                xLIST[i].append(0.0)\n",
    "        \n",
    "        return np.array(xLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
